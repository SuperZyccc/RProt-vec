{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b959c3e1-2cf5-4d14-bf76-ac7f6f33f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698076c-3578-43de-b59a-1bcc06cc54e9",
   "metadata": {},
   "source": [
    "## 数据集ProteinDataset部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b56b48-baf5-4c6d-a353-a39a09e548b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq1 = self.data.iloc[idx, 0]  # 第一个蛋白质序列在第0列\n",
    "        seq2 = self.data.iloc[idx, 1]  # 第二个蛋白质序列在第1列\n",
    "        similarity_score = self.data.iloc[idx, 2]  # 结构相似度评分在第2列\n",
    "\n",
    "        return seq1, seq2, similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cd920-971b-4f81-9e93-4c9a0c9596ce",
   "metadata": {},
   "source": [
    "## Model部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f1dc05-37eb-4f0d-9495-6a6d6984600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_CNN_Block(nn.Module):\n",
    "    def __init__(self, input_size=1024, hidden_size=256, num_layers=1, out_dim=512, dropout=0.1, nheads=4):\n",
    "        super(GRU_CNN_Block, self).__init__()\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(\"../prot_t5_xl_uniref50\", do_lower_case=False)\n",
    "        self.t5model = T5EncoderModel.from_pretrained(\"../prot_t5_xl_uniref50\")\n",
    "        self.t5model.eval()\n",
    "        self.t5model.to(self.device)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gru1 = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.gru2 = nn.GRU(input_size=hidden_size * 2, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                           batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(hidden_size * 2)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size * 2)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.leaky_relu1 = nn.LeakyReLU()\n",
    "        self.leaky_relu2 = nn.LeakyReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=hidden_size * 2, out_channels=hidden_size * 2, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(in_channels=hidden_size * 2, out_channels=hidden_size * 2, kernel_size=7, padding=3)\n",
    "\n",
    "        \n",
    "        self.ln_conv = nn.LayerNorm(hidden_size * 2)\n",
    "        self.dropout_conv = nn.Dropout(dropout)\n",
    "        self.leaky_relu3 = nn.LeakyReLU()\n",
    "\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size*2, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.ln_attn = nn.LayerNorm(hidden_size * 2)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.mlp = nn.Linear(hidden_size * 2, out_dim)\n",
    "\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "\n",
    "    def featurize_prottrans(self, sequences):\n",
    "        sequences = [(\" \".join(seq)) for seq in sequences]\n",
    "        sequences = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences]\n",
    "\n",
    "        ids = self.tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding=True)\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(self.device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = self.t5model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        embedding = embedding.last_hidden_state.cpu().numpy()\n",
    "\n",
    "        features = []\n",
    "        for seq_num in range(len(embedding)):\n",
    "            seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "            seq_emd = embedding[seq_num][:seq_len - 1]\n",
    "            features.append(seq_emd)\n",
    "\n",
    "        max_len = max(feat.shape[0] for feat in features)\n",
    "        features_padded = np.zeros((len(features), max_len, features[0].shape[1]))\n",
    "\n",
    "        for i, feat in enumerate(features):\n",
    "            features_padded[i, :feat.shape[0], :] = feat\n",
    "\n",
    "        prottrans_embedding = torch.tensor(features_padded, dtype=torch.float32).to(self.device)\n",
    "        return prottrans_embedding\n",
    "\n",
    "    def forward(self, seq1, seq2):\n",
    "        seq1_encoded = self.featurize_prottrans(seq1)\n",
    "        seq2_encoded = self.featurize_prottrans(seq2)\n",
    "\n",
    "        # 第一个GRU + LN + Dropout + 激活\n",
    "        x1, _ = self.gru1(seq1_encoded)\n",
    "        x1 = self.ln1(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = self.leaky_relu1(x1)\n",
    "\n",
    "        # 第二个GRU + LN + Dropout + 激活\n",
    "        x1, _ = self.gru2(x1)\n",
    "        x1 = self.ln2(x1)\n",
    "        x1 = self.dropout2(x1)\n",
    "        x1 = self.leaky_relu2(x1)\n",
    "\n",
    "        # 简单的自注意力机制\n",
    "        x1_attn, _ = self.attention(x1, x1, x1)  # Q=K=V=x1\n",
    "        x1 = x1 + x1_attn  # 残差连接\n",
    "        x1 = self.ln_attn(x1)\n",
    "\n",
    "        # 卷积提取局部特征 + 残差连接\n",
    "        residual = x1\n",
    "        conv3_output = self.conv3(x1.transpose(1, 2)).transpose(1, 2)\n",
    "        conv7_output = self.conv7(x1.transpose(1, 2)).transpose(1, 2)\n",
    "        x1 = conv3_output + conv7_output\n",
    "        x1 = self.ln_conv(x1)\n",
    "        x1 = self.dropout_conv(x1)\n",
    "        x1 = self.leaky_relu3(x1)\n",
    "        x1 = x1 + residual\n",
    "\n",
    "        # 池化 + MLP映射\n",
    "        x1 = self.pooling(x1.transpose(1, 2)).squeeze(2)\n",
    "        x1 = self.mlp(x1)\n",
    "\n",
    "        # 对seq2同样处理\n",
    "        x2, _ = self.gru1(seq2_encoded)\n",
    "        x2 = self.ln1(x2)\n",
    "        x2 = self.dropout1(x2)\n",
    "        x2 = self.leaky_relu1(x2)\n",
    "\n",
    "        x2, _ = self.gru2(x2)\n",
    "        x2 = self.ln2(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2 = self.leaky_relu2(x2)\n",
    "\n",
    "        x2_attn, _ = self.attention(x2, x2, x2)\n",
    "        x2 = x2 + x2_attn\n",
    "        x2 = self.ln_attn(x2)\n",
    "\n",
    "        residual = x2\n",
    "        conv3_output = self.conv3(x2.transpose(1, 2)).transpose(1, 2)\n",
    "        conv7_output = self.conv7(x2.transpose(1, 2)).transpose(1, 2)\n",
    "        x2 = conv3_output + conv7_output\n",
    "        x2 = self.ln_conv(x2)\n",
    "        x2 = self.dropout_conv(x2)\n",
    "        x2 = self.leaky_relu3(x2)\n",
    "        x2 = x2 + residual\n",
    "\n",
    "        x2 = self.pooling(x2.transpose(1, 2)).squeeze(2)\n",
    "        x2 = self.mlp(x2)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "    def distance_loss(self, output_seq1, output_seq2, tm_score):\n",
    "        dist_seq = self.cos(output_seq1, output_seq2)\n",
    "        dist_tm = self.l1_loss(dist_seq.unsqueeze(0), tm_score.float().unsqueeze(0))\n",
    "        return dist_tm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2dd2f-5e11-4562-8ff7-402520ca6e8a",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464286ba-7e42-4b73-84ec-fdfbb418cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    seconds = math.ceil(seconds)\n",
    "    delta = datetime.timedelta(seconds=seconds)\n",
    "    return str(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3634d92-936d-43ed-a110-eeb6edf7d686",
   "metadata": {},
   "source": [
    "## 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2478d189-1808-43ac-8179-222a7310ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device, writer, epoch, estimated_step_time, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        batch_start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seq1_batch, seq2_batch, similarity_scores = batch\n",
    "        seq1_batch, seq2_batch, similarity_scores = seq1_batch, seq2_batch, similarity_scores.to(device)\n",
    "        out_seq1, out_seq2 = model(seq1_batch, seq2_batch)\n",
    "        loss = model.distance_loss(out_seq1, out_seq2, similarity_scores)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        print(\"train loss:\", loss.item())\n",
    "\n",
    "        # Log training loss\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(dataloader) + batch_idx)\n",
    "\n",
    "        batch_end_time = time.time()\n",
    "        batch_time = batch_end_time - batch_start_time\n",
    "        print(f\"Epoch {epoch + 1}, Step {batch_idx + 1}/{len(dataloader)}, Step Time: {format_time(batch_time)}\")\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            estimated_step_time = batch_time\n",
    "\n",
    "        if batch_idx % 5000 == 0:\n",
    "            scheduler.step(loss)\n",
    "\n",
    "        avg_step_time = (batch_end_time - start_time) / (batch_idx + 1)\n",
    "        estimated_remaining_time = avg_step_time * (len(dataloader) - batch_idx - 1)\n",
    "        print(f\"Estimated time remaining for this epoch: {format_time(estimated_remaining_time)}\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch + 1} training time: {format_time(epoch_time)}\")\n",
    "\n",
    "    return total_loss / len(dataloader), epoch_time, estimated_step_time\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, device, writer, epoch, estimated_step_time):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        batch_start_time = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            seq1_batch, seq2_batch, similarity_scores = batch\n",
    "            seq1_batch, seq2_batch, similarity_scores = seq1_batch, seq2_batch, similarity_scores.to(device)\n",
    "            out_seq1, out_seq2 = model(seq1_batch, seq2_batch)\n",
    "            loss = model.distance_loss(out_seq1, out_seq2, similarity_scores)\n",
    "            total_loss += loss.item()\n",
    "            print(\"val loss:\", loss.item())\n",
    "\n",
    "            # Log validation loss\n",
    "            writer.add_scalar('Loss/val', loss.item(), epoch * len(dataloader) + batch_idx)\n",
    "\n",
    "        batch_end_time = time.time()\n",
    "        batch_time = batch_end_time - batch_start_time\n",
    "        print(f\"Epoch {epoch + 1}, Step {batch_idx + 1}/{len(dataloader)}, Step Time: {format_time(batch_time)}\")\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            estimated_step_time = batch_time\n",
    "\n",
    "        avg_step_time = (batch_end_time - start_time) / (batch_idx + 1)\n",
    "        estimated_remaining_time = avg_step_time * (len(dataloader) - batch_idx - 1)\n",
    "        print(f\"Estimated time remaining for this epoch: {format_time(estimated_remaining_time)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch + 1} validation time: {format_time(epoch_time)}\")\n",
    "\n",
    "    return total_loss / len(dataloader), epoch_time, estimated_step_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5dc0a9-c64b-4cf7-94ac-123a213edd1d",
   "metadata": {},
   "source": [
    "## 训练主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed72e90e-d91f-4133-8831-3a68df48f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, checkpoint_dir, best_loss, num_checkpoints=1):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}_loss_{best_loss:.4f}.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': best_loss,\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    # Manage number of checkpoints\n",
    "    checkpoints = sorted(os.listdir(checkpoint_dir), key=lambda x: os.path.getmtime(os.path.join(checkpoint_dir, x)))\n",
    "    while len(checkpoints) > num_checkpoints:\n",
    "        os.remove(os.path.join(checkpoint_dir, checkpoints.pop(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642073ee-86af-4348-8853-0a4d513732cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 加载数据集\n",
    "    csv_file = '../data/data.csv'\n",
    "    dataset = ProteinDataset(csv_file)\n",
    "\n",
    "    # 划分训练集和验证集\n",
    "    train_size = int(0.95 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 加载模型\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GRU_CNN_Block().to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "    # TensorBoard\n",
    "    writer = SummaryWriter(log_dir='../../tf-logs/Training')\n",
    "\n",
    "\n",
    "    # 检查点目录\n",
    "    checkpoint_dir = 'checkpoints/'\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    # 训练模型\n",
    "    num_epochs = 2\n",
    "    best_val_loss = float('inf')\n",
    "    total_train_time = 0\n",
    "    total_val_time = 0\n",
    "\n",
    "    # 初始估算 step 时间\n",
    "    estimated_step_time = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_time, estimated_step_time = train_epoch(model, train_dataloader, optimizer, device, writer,\n",
    "                                                                  epoch, estimated_step_time, scheduler)\n",
    "        val_loss, val_time, estimated_step_time = validate_epoch(model, val_dataloader, device, writer, epoch,\n",
    "                                                                 estimated_step_time)\n",
    "\n",
    "        total_train_time += train_time\n",
    "        total_val_time += val_time\n",
    "        avg_train_time = total_train_time / (epoch + 1)\n",
    "        avg_val_time = total_val_time / (epoch + 1)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(\n",
    "            f\"Estimated time remaining: {format_time(avg_train_time * (num_epochs - epoch - 1) + avg_val_time * (num_epochs - epoch - 1))}\")\n",
    "\n",
    "        # 保存最好的模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_checkpoint(model, optimizer, epoch + 1, checkpoint_dir, best_val_loss)\n",
    "\n",
    "    # 保存最终模型\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    writer.close()\n",
    "    print(\"Training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9859ade-61ec-408c-a004-9b372e17d47c",
   "metadata": {},
   "source": [
    "## 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65de6f-df1a-44a1-86f8-c14aa81bfd7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d9956-ce40-4056-b2e3-3b550a3b6cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818f46b-ca03-4344-bb21-8688262a2678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
